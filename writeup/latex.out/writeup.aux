\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}MNIST Dataset}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Hyperparameter Sets}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Hyperparameter Sets}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Rice Dataset}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Hyperparameter Sets}{1}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The results for the hyperparameter tuning step on the MLP architecture trained on the rice dataset. The best epoch is used for each hyperparameter setting.}}{1}{}\protected@file@percent }
\newlabel{tab:mnist_nn}{{1}{1}{}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The results for the hyperparameter tuning step on the random forest architecture trained on the rice dataset. The best epoch is used for each hyperparameter setting.}}{2}{}\protected@file@percent }
\newlabel{tab:mnist_random_forest}{{2}{2}{}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The results for the hyperparameter tuning step on the MLP architecture trained on the rice dataset. The best epoch is used for each hyperparameter setting.}}{2}{}\protected@file@percent }
\newlabel{tab:rice_nn}{{3}{2}{}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The results for the hyperparameter tuning step on the Random Forest architecture trained on the rice dataset. The best ntree value is used for each hyperparameter setting.}}{3}{}\protected@file@percent }
\newlabel{tab:rice_random_forest}{{4}{3}{}{table.4}{}}
\gdef \@abspage@last{3}
